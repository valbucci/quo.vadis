{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulation Reports Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repo Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_ROOT = Path(\"../../\")\n",
    "sys.path.append(REPO_ROOT.as_posix())\n",
    "\n",
    "from preprocessing.reports import report_to_apiseq\n",
    "from preprocessing.array import rawseq2array\n",
    "from utils.functions import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Call Sequences\n",
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHA256_PATTERN = r'[a-f0-9]{64}'\n",
    "\n",
    "def get_name_stem(file_path) -> str:\n",
    "    \"\"\"\n",
    "    Get the base name stem from a file path.\n",
    "        e.g. \"path/to/file/stem.ext\" -> \"stem\"\n",
    "\n",
    "    Args:\n",
    "        file_path (str|Path): The path, or the file name.\n",
    "\n",
    "    Returns:\n",
    "        str: The base name stem, which is the file name excluding the path\n",
    "            and the extension.\n",
    "    \"\"\"\n",
    "    base_name = Path(file_path).name\n",
    "    return base_name.split(\".\")[0]\n",
    "\n",
    "\n",
    "def get_api_sequences(emulation_dataset_path: Path, \n",
    "                      skip_clean=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract the sequence of API calls and associated family class, given the \n",
    "    base path to the emulation dataset folder containing the JSON-formatted \n",
    "    reports. Each family class should be named `report_<FAMILY_CLASS>`, where\n",
    "    <FAMILY_CLASS> could be e.g. \"ransomware\" or \"clean\". Furthermore, each\n",
    "    emulation report should be named as `<SHA256>.json`, where <SHA256> is the\n",
    "    digest of the corresponding PE binary.\n",
    "\n",
    "    Args:\n",
    "        emulation_dataset_path (Path): base path to the emulation dataset. \n",
    "        skip_clean (bool, optional): flag for skipping the extraction of API\n",
    "            calls by benignware. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Table containing the extracted information structured as:\n",
    "            - pe_hash (str): the sha256 digest of the PE binary;\n",
    "            - family (str): the family class of the executable;\n",
    "            - api_sequence (list[str]): the sequence of API calls. \n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(\"get_api_sequences\")\n",
    "\n",
    "    assert emulation_dataset_path.exists()\n",
    "    api_sequences = []\n",
    "    \n",
    "    # Iterate over every malware family folder\n",
    "    # (includes benignware in \"report_clean\")\n",
    "    for family_reports_dir in emulation_dataset_path.glob(\"report_*\"):\n",
    "        family_name = family_reports_dir.name.split(\"_\")[-1]\n",
    "        if skip_clean and family_name == \"clean\":\n",
    "            # Skip benignware reports\n",
    "            logger.info(f\"Skipping benignware ...\")\n",
    "            continue\n",
    "        \n",
    "        logger.info(f\"Getting family '{family_name}' ...\")\n",
    "        \n",
    "        # Iterate over all JSON files in the family folder\n",
    "        # (files with extension `.err` are empty)\n",
    "        for report_path in family_reports_dir.glob(\"*.json\"):\n",
    "            malware_hash = get_name_stem(report_path)\n",
    "            if re.match(SHA256_PATTERN, malware_hash) is None:\n",
    "                # If the filename is not SHA256 it's not an emulation report\n",
    "                logger.warning(f\"Skipping non-SHA256 '{report_path}' ...\")\n",
    "                continue\n",
    "            \n",
    "            report_features = report_to_apiseq(report_path)\n",
    "            api_sequence = tuple(report_features[\"api.seq\"])\n",
    "            assert report_features[\"api.seq.len\"] == len(api_sequence)\n",
    "\n",
    "            api_sequences.append((malware_hash, family_name, api_sequence))\n",
    "        \n",
    "    return pd.DataFrame(api_sequences, columns=[\"pe_hash\", \"family\", \n",
    "                                                \"api_sequence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pe_hash</th>\n",
       "      <th>api_sequence</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00004fa66d2c7f7bd21bedcc4c6db127684ef4ee2725c6...</td>\n",
       "      <td>(kernel32.getsystemtimeasfiletime, kernel32.ge...</td>\n",
       "      <td>(clean,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001d0c1054136e470d7742aef8bab28af29c9187f6103...</td>\n",
       "      <td>(msvcrt.__set_app_type, msvcrt.__p__fmode, msv...</td>\n",
       "      <td>(dropper,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002229c96f323e973c59f4f891bd529027a520846b131...</td>\n",
       "      <td>(kernel32.getsystemtimeasfiletime, kernel32.ge...</td>\n",
       "      <td>(keylogger,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00029544a86c16fdc6f6d2e78a3931e830f0c93eb39fef...</td>\n",
       "      <td>(kernel32.getmodulehandlew, kernel32.setthread...</td>\n",
       "      <td>(clean,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00029a5f91accf32eaa4aab3c661e115424ad5336164fc...</td>\n",
       "      <td>(kernel32.getmodulehandlea, user32.getkeyboard...</td>\n",
       "      <td>(trojan,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90020</th>\n",
       "      <td>fffc3b392021a16b621e4aacf10a1483bd940f9befb077...</td>\n",
       "      <td>(kernel32.getsystemtimeasfiletime, kernel32.ge...</td>\n",
       "      <td>(coinminer,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90021</th>\n",
       "      <td>fffdd200ba06ae0bc51ee77f91d7ccf830ae1703ccec21...</td>\n",
       "      <td>(kernel32.getsystemtimeasfiletime, kernel32.ge...</td>\n",
       "      <td>(clean,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90022</th>\n",
       "      <td>fffdef1712ef3713d1895390a0115319eac9afb69a73fd...</td>\n",
       "      <td>(kernel32.getsystemtimeasfiletime, kernel32.ge...</td>\n",
       "      <td>(coinminer,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90023</th>\n",
       "      <td>fffecf791b7337eae1f02531f34d41ea95fbaaffdaa9a8...</td>\n",
       "      <td>(kernel32.getsystemtimeasfiletime, kernel32.ge...</td>\n",
       "      <td>(dropper,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90024</th>\n",
       "      <td>ffffab5b653416cde9ec4a6893627781a8982f3b8cb26f...</td>\n",
       "      <td>(kernel32.heapsetinformation, kernel32.getmodu...</td>\n",
       "      <td>(clean,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90025 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 pe_hash  \\\n",
       "0      00004fa66d2c7f7bd21bedcc4c6db127684ef4ee2725c6...   \n",
       "1      0001d0c1054136e470d7742aef8bab28af29c9187f6103...   \n",
       "2      0002229c96f323e973c59f4f891bd529027a520846b131...   \n",
       "3      00029544a86c16fdc6f6d2e78a3931e830f0c93eb39fef...   \n",
       "4      00029a5f91accf32eaa4aab3c661e115424ad5336164fc...   \n",
       "...                                                  ...   \n",
       "90020  fffc3b392021a16b621e4aacf10a1483bd940f9befb077...   \n",
       "90021  fffdd200ba06ae0bc51ee77f91d7ccf830ae1703ccec21...   \n",
       "90022  fffdef1712ef3713d1895390a0115319eac9afb69a73fd...   \n",
       "90023  fffecf791b7337eae1f02531f34d41ea95fbaaffdaa9a8...   \n",
       "90024  ffffab5b653416cde9ec4a6893627781a8982f3b8cb26f...   \n",
       "\n",
       "                                            api_sequence        family  \n",
       "0      (kernel32.getsystemtimeasfiletime, kernel32.ge...      (clean,)  \n",
       "1      (msvcrt.__set_app_type, msvcrt.__p__fmode, msv...    (dropper,)  \n",
       "2      (kernel32.getsystemtimeasfiletime, kernel32.ge...  (keylogger,)  \n",
       "3      (kernel32.getmodulehandlew, kernel32.setthread...      (clean,)  \n",
       "4      (kernel32.getmodulehandlea, user32.getkeyboard...     (trojan,)  \n",
       "...                                                  ...           ...  \n",
       "90020  (kernel32.getsystemtimeasfiletime, kernel32.ge...  (coinminer,)  \n",
       "90021  (kernel32.getsystemtimeasfiletime, kernel32.ge...      (clean,)  \n",
       "90022  (kernel32.getsystemtimeasfiletime, kernel32.ge...  (coinminer,)  \n",
       "90023  (kernel32.getsystemtimeasfiletime, kernel32.ge...    (dropper,)  \n",
       "90024  (kernel32.heapsetinformation, kernel32.getmodu...      (clean,)  \n",
       "\n",
       "[90025 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "family\n",
       "(clean,)              25291\n",
       "(trojan,)             11961\n",
       "(dropper,)            10888\n",
       "(backdoor,)           10494\n",
       "(ransomware,)          9627\n",
       "(rat,)                 9467\n",
       "(coinminer,)           6893\n",
       "(keylogger,)           4573\n",
       "(backdoor, trojan)      567\n",
       "(dropper, trojan)       252\n",
       "(dropper, rat)           10\n",
       "(backdoor, rat)           1\n",
       "(keylogger, rat)          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMULATION_DATASET_PATH = REPO_ROOT.joinpath(\"data/emulation.dataset\")\n",
    "PRELOADED_APIS_PATH = Path(\"./api_sequences.pickle\")\n",
    "\n",
    "reports_df = None\n",
    "if PRELOADED_APIS_PATH.exists():\n",
    "    reports_df = pd.read_pickle(PRELOADED_APIS_PATH)\n",
    "else:\n",
    "    reports_df = get_api_sequences(EMULATION_DATASET_PATH)\n",
    "    reports_df.to_pickle(PRELOADED_APIS_PATH)\n",
    "\n",
    "# Account for multiple classes\n",
    "reports_df = reports_df.groupby(\n",
    "    [\"pe_hash\", \"api_sequence\"])[\"family\"].apply(tuple).reset_index()\n",
    "\n",
    "display(reports_df)\n",
    "display(reports_df[\"family\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "We encode the input vector *X*, consisting of the API call sequences:\n",
    "1. Get the list of API sequences and count which APIs are the most frequent.\n",
    "2. Retain only the $V$ most occurring APIs, where $V$ is the vocabulary size.\n",
    "    - Default is $V=150$, but published paper selects $V=600$.\n",
    "3. Assign a numeric label to each API.\n",
    "    - The lower the number, the most frequent the use of that API.\n",
    "    - The higher the number, the more that API is encountered rarely.\n",
    "    - Counter starts at 2. I still need to fully understand this:\n",
    "        - 0 -> padding;\n",
    "        - 1 -> rare APIs (e.g. rarer than $V$ ..?)\n",
    "        - So then why aren't the least frequent APIs encoded with lower numbers?\n",
    "4. Define a padding length\n",
    "    - The repo's default value is 150.\n",
    "    - Based on the model scheme in the published paper padding seems to be 96.\n",
    "    - But the emulation reports stop after recording 500 API calls.\n",
    "    - **So which one is it?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_VOCABULARY_SIZE = 600\n",
    "PADDING_LENGTH = 150\n",
    "\n",
    "def preprocess_api_sequences(api_sequences: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Encodes sequences of API calls to integer values based on a globally-defined \n",
    "    vocabulary size (V) and padding length.\n",
    "    \n",
    "    0      -> Reserved for padding.\n",
    "    1      -> For APIs rarer than V most frequently occurring APIs.\n",
    "    2..V+2 -> APIs ranked based on their frequency of occurrence, with the most\n",
    "                  frequent APIs being encoded with lower values.\n",
    "\n",
    "    Args:\n",
    "        api_sequences (np.ndarray): Dataset as bi-dimensional array where each \n",
    "            row contains the sequence of API calls made by one sample.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The API sequences encoded as integers within [0, V+2].\n",
    "    \"\"\"\n",
    "      \n",
    "    # Retain only the V most occurring APIs, where V is the vocabulary size  \n",
    "    api_counter = Counter(flatten(api_sequences))\n",
    "    apis_preserved = [\n",
    "        x[0] for x in api_counter.most_common(API_VOCABULARY_SIZE)]\n",
    "    \n",
    "    # Encode each API with numeric value\n",
    "    api_map = dict(zip(apis_preserved, range(2, API_VOCABULARY_SIZE+2)))\n",
    "    \n",
    "    return np.vstack([rawseq2array(x, api_map, PADDING_LENGTH) \n",
    "                      for x in api_sequences])\n",
    "    \n",
    "\n",
    "def get_labels_map(labels: Iterable) -> dict:\n",
    "    \"\"\"Converts series of unique labels to map where label -> index\"\"\"\n",
    "    return dict([(label, index) for index, label in enumerate(labels)])\n",
    "\n",
    "\n",
    "def get_labels_list(labelled_data: Iterable) -> list:\n",
    "    \"\"\"\n",
    "    Removes duplicates from labelled data and returns a list with the 'clean' \n",
    "    label in the first place\n",
    "    \"\"\"\n",
    "    labels = list(set(flatten(labelled_data)))\n",
    "    \n",
    "    # Sort list to get consistent results\n",
    "    labels = sorted(labels)\n",
    "    \n",
    "    # I like having the \"clean\" label as the first in the list\n",
    "    if \"clean\" in labels:\n",
    "        labels.remove(\"clean\")\n",
    "        labels.insert(0, \"clean\")\n",
    "        \n",
    "    return labels\n",
    "\n",
    "\n",
    "def encode_labels(labelled_data: Iterable, labels_map: dict) -> list:\n",
    "    labels_encoded = []\n",
    "    for label_tuple in labelled_data:\n",
    "        labels_encoded.append(labels_map[label_tuple[0]])\n",
    "        \n",
    "    return np.ndarray(labels_encoded)\n",
    "\n",
    "    \n",
    "def preprocess_labels(labelled_data: Iterable) -> np.ndarray:\n",
    "    \"\"\"Encodes dataset of labels to integer values\"\"\"\n",
    "    labels = get_labels_list(labelled_data)\n",
    "    \n",
    "    # Encode all family classes with numeric values\n",
    "    labels_map = get_labels_map(labels)\n",
    "    return encode_labels(labelled_data, labels_map)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "maximum supported dimension for an ndarray is 32, found 90025",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m PREPROCESSED_PATH \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./encoded_api_sequences.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m preprocess_api_sequences(reports_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_sequence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m----> 4\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreports_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfamily\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)\n\u001b[1;32m      8\u001b[0m full_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([X, y])\n",
      "Cell \u001b[0;32mIn[26], line 71\u001b[0m, in \u001b[0;36mpreprocess_labels\u001b[0;34m(labelled_data)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Encode all family classes with numeric values\u001b[39;00m\n\u001b[1;32m     70\u001b[0m labels_map \u001b[38;5;241m=\u001b[39m get_labels_map(labels)\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencode_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabelled_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 62\u001b[0m, in \u001b[0;36mencode_labels\u001b[0;34m(labelled_data, labels_map)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label_tuple \u001b[38;5;129;01min\u001b[39;00m labelled_data:\n\u001b[1;32m     60\u001b[0m     labels_encoded\u001b[38;5;241m.\u001b[39mappend(labels_map[label_tuple[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_encoded\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: maximum supported dimension for an ndarray is 32, found 90025"
     ]
    }
   ],
   "source": [
    "PREPROCESSED_PATH = Path(\"./encoded_api_sequences.pickle\")\n",
    "\n",
    "X = preprocess_api_sequences(reports_df[\"api_sequence\"].values)\n",
    "y = preprocess_labels(reports_df[\"family\"].values)\n",
    "\n",
    "assert len(X) == len(y)\n",
    "\n",
    "full_dataset = tuple([X, y])\n",
    "\n",
    "with open(PREPROCESSED_PATH, \"wb\") as preprocessed_file:\n",
    "    pickle.dump(full_dataset, preprocessed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valbux/Software/miniconda/3.12/envs/EmulationMLTraining/lib/python3.12/site-packages/sklearn/manifold/_t_sne.py:1162: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Prepare the labels for coloring\u001b[39;00m\n\u001b[1;32m     18\u001b[0m mlb \u001b[38;5;241m=\u001b[39m MultiLabelBinarizer()\n\u001b[0;32m---> 19\u001b[0m y_combined_bin \u001b[38;5;241m=\u001b[39m \u001b[43mmlb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_combined\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Software/miniconda/3.12/envs/EmulationMLTraining/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Software/miniconda/3.12/envs/EmulationMLTraining/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:819\u001b[0m, in \u001b[0;36mMultiLabelBinarizer.fit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    817\u001b[0m class_mapping \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    818\u001b[0m class_mapping\u001b[38;5;241m.\u001b[39mdefault_factory \u001b[38;5;241m=\u001b[39m class_mapping\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m\n\u001b[0;32m--> 819\u001b[0m yt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# sort classes and reorder columns\u001b[39;00m\n\u001b[1;32m    822\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(class_mapping, key\u001b[38;5;241m=\u001b[39mclass_mapping\u001b[38;5;241m.\u001b[39mget)\n",
      "File \u001b[0;32m~/Software/miniconda/3.12/envs/EmulationMLTraining/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:892\u001b[0m, in \u001b[0;36mMultiLabelBinarizer._transform\u001b[0;34m(self, y, class_mapping)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m labels \u001b[38;5;129;01min\u001b[39;00m y:\n\u001b[1;32m    891\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 892\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[1;32m    893\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    894\u001b[0m             index\u001b[38;5;241m.\u001b[39madd(class_mapping[label])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Combine training and testing data for visualization\n",
    "X_combined_vect = np.vstack((X_train, X_test))\n",
    "# y_combined = np.hstack([\n",
    "#     [family[0] for family in y_train], \n",
    "#     [family[0] for family in y_test]\n",
    "# ])\n",
    "y_combined = np.concatenate()\n",
    "\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, n_iter=2000)\n",
    "X_embedded = tsne.fit_transform(X_combined_vect)\n",
    "\n",
    "# Prepare the labels for coloring\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_combined_bin = mlb.fit_transform(y_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_labels(labelled_data: Iterable, labels_decoder: dict) -> np.ndarray:\n",
    "    labels_decoded = []\n",
    "    for labels in labelled_data:\n",
    "        for label in labels:\n",
    "            labels_decoded.append(np.array([labels_decoder[label]]))\n",
    "            \n",
    "    return np.array(labels_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_combined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m primary_labels \u001b[38;5;241m=\u001b[39m [labels_decoder[labels[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m labels \u001b[38;5;129;01min\u001b[39;00m \u001b[43my_combined\u001b[49m]\n\u001b[1;32m      2\u001b[0m label_to_color \u001b[38;5;241m=\u001b[39m {label: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mset\u001b[39m(primary_labels))}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Map labels to colors\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_combined' is not defined"
     ]
    }
   ],
   "source": [
    "labels_map = get_labels_map(get_labels_list(reports_df[\"family\"].values))\n",
    "labels_decoder = {value: key for (key, value) in labels_map.items()}\n",
    "\n",
    "\n",
    "primary_labels = [labels_decoder[labels[0]] for labels in y_combined]\n",
    "label_to_color = {label: idx for idx, label in enumerate(set(primary_labels))}\n",
    "\n",
    "# Map labels to colors\n",
    "colors = [label_to_color[label] for label in primary_labels]\n",
    "\n",
    "# Plot the t-SNE results\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=colors, \n",
    "                      cmap='tab10', alpha=0.7)\n",
    "\n",
    "# Create a legend\n",
    "handles, _ = scatter.legend_elements(num=len(label_to_color))\n",
    "plt.legend(handles, label_to_color.keys(), title=\"Malware Families\", \n",
    "           bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.title('t-SNE Visualization of Enumeration-Embedded API Call Sequences')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EmulationMLTraining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
